"""
Manages and rotates Gemini API keys to provide resilient access to the AI model.

This module contains two key classes: `ApiKeyManager` and `ResilientGeminiModel`.
The `ApiKeyManager` is responsible for maintaining a pool of API keys in memory,
cycling through them, and marking keys as broken if they fail. The
`ResilientGeminiModel` acts as a proxy to the actual Gemini model, using the
`ApiKeyManager` to automatically retry API calls with a new key upon encountering
quota or permission errors. This makes the application more robust and able to
withstand single-key failures.
"""
import itertools
import logging
from typing import Dict, List, Any, Optional

import google.generativeai as genai
from google.api_core import exceptions as google_exceptions

logger = logging.getLogger(__name__)


class ResilientGeminiModel:
    """
    A proxy wrapper for the Gemini model that enhances resilience.

    This class automatically handles API key rotation on specific failures,
    such as quota errors or permission issues, by collaborating with an
    `ApiKeyManager` instance. It ensures that if one key fails, the system
    seamlessly switches to the next available key.

    Attributes:
        _key_manager (ApiKeyManager): The manager responsible for providing API keys.
        _agent_name (str): The name of the agent using this model, for logging.
        _is_json_model (bool): Flag indicating if the model should be configured for JSON output.
        _current_key (Optional[str]): The API key currently in use.
        _current_model (Optional[genai.GenerativeModel]): The active Gemini model instance.
    """
    def __init__(self, key_manager: 'ApiKeyManager', agent_name: str, is_json_model: bool):
        """
        Initializes the ResilientGeminiModel.

        Args:
            key_manager: An instance of `ApiKeyManager` to handle key rotation.
            agent_name: A name for the agent using this model, for logging purposes.
            is_json_model: If True, configures the model to expect JSON output.
        """
        self._key_manager = key_manager
        self._agent_name = agent_name
        self._is_json_model = is_json_model
        
        self._current_key: Optional[str] = None
        self._current_model: Optional[genai.GenerativeModel] = None
        
        # Initialize the first model with the first valid key
        self._get_new_model()

    def _get_new_model(self):
        """
        Fetches the next valid API key and creates a new model instance.

        This private method is called during initialization and whenever the
        current API key is marked as broken. It raises a `RuntimeError` if
        no valid keys are left.

        Raises:
            RuntimeError: If all available API keys have failed.
        """
        self._current_key = self._key_manager.get_next_key()
        if self._current_key is None:
            self._current_model = None
            raise RuntimeError(f"All available Gemini API keys have failed for agent '{self._agent_name}'.")

        logger.info(f"Agent '{self._agent_name}' is now using a new API key ending in ...{self._current_key[-4:]}")
        genai.configure(api_key=self._current_key)
        
        # Configure the model based on whether JSON output is required
        if self._is_json_model:
            self._current_model = genai.GenerativeModel(
                'gemini-2.5-flash-lite',
                generation_config={"response_mime_type": "application/json"}
            )
        else:
            self._current_model = genai.GenerativeModel('gemini-2.5-flash-lite') # Updated model name

    def generate_content(self, *args, **kwargs) -> Any:
        """
        Wraps the model's `generate_content` call with retry logic.

        This method attempts an API call and, if it fails due to a quota or
        permission error, it marks the current key as broken and retries with
        a new key. This cycle continues until a call succeeds or all keys fail.

        Args:
            *args: Positional arguments to be passed to the underlying model's
                   `generate_content` method.
            **kwargs: Keyword arguments to be passed to the underlying model's
                      `generate_content` method.

        Returns:
            The content generated by the model.

        Raises:
            RuntimeError: If no valid model is available or if all API keys
                          fail in succession.
        """
        if self._current_model is None:
            raise RuntimeError(f"No valid model available for agent '{self._agent_name}'. All keys may be broken.")

        # The number of retries is limited by the number of initially valid keys.
        for attempt in range(self._key_manager.get_valid_key_count()):
            try:
                # Attempt the API call with the current model
                return self._current_model.generate_content(*args, **kwargs)
            
            except (google_exceptions.ResourceExhausted, google_exceptions.PermissionDenied) as e:
                error_type = "Quota Exceeded (ResourceExhausted)" if isinstance(e, google_exceptions.ResourceExhausted) else "Permission Denied"
                logger.warning(f"{error_type} for agent '{self._agent_name}' with key ending in ...{self._current_key[-4:]}. Marking key as broken and rotating.")
                
                # Mark the failed key as broken for the current session
                self._key_manager.mark_key_as_broken(self._current_key)
                
                # Try to get a new model with the next available key
                try:
                    self._get_new_model()
                except RuntimeError:
                    # This happens if we've run out of keys
                    logger.error(f"All available keys have failed. Raising final exception for agent '{self._agent_name}'.")
                    raise e # Re-raise the last caught exception
                
                # If we successfully got a new model, the loop will continue and retry the call.

        # If the loop finishes without a successful return, it means all keys were tried and failed.
        raise RuntimeError(f"Failed to get a response for agent '{self._agent_name}' after trying all available API keys.")


class ApiKeyManager:
    """
    Manages and rotates Gemini API keys entirely in memory.

    This class is designed to be stateless, making it ideal for serverless
    environments. It tracks the status of keys (broken or not) only for the
    duration of its instance's lifetime, without persisting this state.

    Attributes:
        _keys (List[Dict[str, Any]]): A list of dictionaries, each representing an API key.
        _key_cycle (itertools.cycle): An iterator that cycles through the keys.
    """

    def __init__(self, gemini_keys: Dict[str, str]):
        """
        Initializes the ApiKeyManager with a dictionary of keys.

        Args:
            gemini_keys: A dictionary where keys are names and values are the API keys.

        Raises:
            ValueError: If the `gemini_keys` dictionary is empty or no valid keys are loaded.
        """
        if not gemini_keys:
            raise ValueError("Gemini API key dictionary cannot be empty.")

        # Initialize all keys with a 'is_broken' status of False.
        # The status is only tracked in memory for this instance's lifetime.
        self._keys: List[Dict[str, Any]] = [
            {"value": key_value, "is_broken": False}
            for key_name, key_value in gemini_keys.items()
        ]

        if not self._keys:
            raise ValueError("No valid Gemini API keys were loaded from the configuration.")

        # The cycler will loop through the list of keys indefinitely.
        self._key_cycle = itertools.cycle(self._keys)
        logger.info(f"ApiKeyManager initialized with {len(self._keys)} Gemini API key(s).")

    def mark_key_as_broken(self, key_value: str):
        """
        Marks a specific key as broken in memory for the current session.

        Args:
            key_value: The API key string to be marked as broken.
        """
        for key_info in self._keys:
            if key_info['value'] == key_value:
                if not key_info['is_broken']:
                    key_info['is_broken'] = True
                    logger.warning(f"Marked key ending in ...{key_value[-4:]} as broken for this session.")
                break

    def get_next_key(self) -> Optional[str]:
        """
        Gets the next valid (not broken) Gemini key from the in-memory list.

        Returns:
            The next valid API key as a string, or None if all keys have been
            marked as broken.
        """
        if self.get_valid_key_count() == 0:
            logger.error("All Gemini keys are marked as broken for this session.")
            return None

        # Cycle through the keys until a non-broken one is found.
        # We loop at most the total number of keys to avoid an infinite loop.
        for _ in range(len(self._keys)):
            key_info = next(self._key_cycle)
            if not key_info['is_broken']:
                return key_info['value']
        
        # This should not be reached if get_valid_key_count() > 0, but is a safeguard.
        return None

    def create_ai_model(self, agent_name: str = "default") -> ResilientGeminiModel:
        """
        Creates a resilient Gemini client instance configured for JSON output.

        This is typically used for specialist agents that require structured data.

        Args:
            agent_name: The name of the agent that will use this model.

        Returns:
            An instance of `ResilientGeminiModel` configured for JSON.
        """
        return ResilientGeminiModel(key_manager=self, agent_name=agent_name, is_json_model=True)

    def create_chat_model(self, agent_name: str = "default") -> ResilientGeminiModel:
        """
        Creates a resilient Gemini client instance for natural language chat.

        This is used for agents that interact directly with the user in a
        conversational manner.

        Args:
            agent_name: The name of the agent that will use this model.

        Returns:
            An instance of `ResilientGeminiModel` configured for natural language.
        """
        return ResilientGeminiModel(key_manager=self, agent_name=agent_name, is_json_model=False)

    def get_key_count(self) -> int:
        """
        Returns the total number of API keys loaded into the manager.

        Returns:
            The total count of keys.
        """
        return len(self._keys)

    def get_valid_key_count(self) -> int:
        """
        Returns the number of keys not marked as broken in this session.

        Returns:
            The count of valid, usable keys.
        """
        return sum(1 for key in self._keys if not key['is_broken'])